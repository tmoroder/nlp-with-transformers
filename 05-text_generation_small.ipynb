{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acadc9da",
   "metadata": {},
   "source": [
    "# 05 - Text Generation Small\n",
    "Uses only the small model, the large one does not fit into my GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490599c",
   "metadata": {},
   "source": [
    "## Greedy Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64cbc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac4596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model_name = \"gpt2-xl\"\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4297b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95be714",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = \"Transformers are the\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f38428",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids)\n",
    "        # logit of first batch and last token\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "        # store tokens with highest proba\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
    "            )\n",
    "            iteration[f\"Choice {choice_idx + 1}\"] = token_choice\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b50c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>most (9.76%)</td>\n",
       "      <td>same (2.94%)</td>\n",
       "      <td>only (2.87%)</td>\n",
       "      <td>best (2.38%)</td>\n",
       "      <td>first (1.77%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the most</td>\n",
       "      <td>common (22.90%)</td>\n",
       "      <td>powerful (6.88%)</td>\n",
       "      <td>important (6.32%)</td>\n",
       "      <td>popular (3.95%)</td>\n",
       "      <td>commonly (2.14%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the most common</td>\n",
       "      <td>type (15.06%)</td>\n",
       "      <td>types (3.31%)</td>\n",
       "      <td>form (1.91%)</td>\n",
       "      <td>way (1.89%)</td>\n",
       "      <td>and (1.49%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the most common type</td>\n",
       "      <td>of (83.13%)</td>\n",
       "      <td>in (3.16%)</td>\n",
       "      <td>. (1.92%)</td>\n",
       "      <td>, (1.63%)</td>\n",
       "      <td>for (0.88%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the most common type of</td>\n",
       "      <td>particle (1.55%)</td>\n",
       "      <td>object (1.02%)</td>\n",
       "      <td>light (0.71%)</td>\n",
       "      <td>energy (0.67%)</td>\n",
       "      <td>objects (0.66%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the most common type of particle</td>\n",
       "      <td>. (14.26%)</td>\n",
       "      <td>in (11.57%)</td>\n",
       "      <td>that (10.19%)</td>\n",
       "      <td>, (9.57%)</td>\n",
       "      <td>accelerator (5.81%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the most common type of parti...</td>\n",
       "      <td>They (17.48%)</td>\n",
       "      <td>\\n (15.19%)</td>\n",
       "      <td>The (7.06%)</td>\n",
       "      <td>These (3.09%)</td>\n",
       "      <td>In (3.07%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the most common type of parti...</td>\n",
       "      <td>are (38.78%)</td>\n",
       "      <td>have (8.14%)</td>\n",
       "      <td>can (7.98%)</td>\n",
       "      <td>'re (5.04%)</td>\n",
       "      <td>consist (1.57%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input           Choice 1  \\\n",
       "0                               Transformers are the       most (9.76%)   \n",
       "1                          Transformers are the most    common (22.90%)   \n",
       "2                   Transformers are the most common      type (15.06%)   \n",
       "3              Transformers are the most common type        of (83.13%)   \n",
       "4           Transformers are the most common type of   particle (1.55%)   \n",
       "5  Transformers are the most common type of particle         . (14.26%)   \n",
       "6  Transformers are the most common type of parti...      They (17.48%)   \n",
       "7  Transformers are the most common type of parti...       are (38.78%)   \n",
       "\n",
       "            Choice 2            Choice 3          Choice 4  \\\n",
       "0       same (2.94%)        only (2.87%)      best (2.38%)   \n",
       "1   powerful (6.88%)   important (6.32%)   popular (3.95%)   \n",
       "2      types (3.31%)        form (1.91%)       way (1.89%)   \n",
       "3         in (3.16%)           . (1.92%)         , (1.63%)   \n",
       "4     object (1.02%)       light (0.71%)    energy (0.67%)   \n",
       "5        in (11.57%)       that (10.19%)         , (9.57%)   \n",
       "6        \\n (15.19%)         The (7.06%)     These (3.09%)   \n",
       "7       have (8.14%)         can (7.98%)       're (5.04%)   \n",
       "\n",
       "               Choice 5  \n",
       "0         first (1.77%)  \n",
       "1      commonly (2.14%)  \n",
       "2           and (1.49%)  \n",
       "3           for (0.88%)  \n",
       "4       objects (0.66%)  \n",
       "5   accelerator (5.81%)  \n",
       "6            In (3.07%)  \n",
       "7       consist (1.57%)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86378501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are the most common type of particle. They are\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecdffbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "\"The unicorns were very intelligent, and they were very intelligent,\" said Dr. David S. Siegel, a professor of anthropology at the University of California, Berkeley. \"They were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andes Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61823ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 + 8 => 13 \n",
      "7 + 2 => 9 \n",
      "1 + 0 => 10 \n",
      "1 + 1 => 11 \n",
      "1 + 2 => 12 \n",
      "1 + 3 => 13 \n",
      "1 + 4 => 14 \n",
      "1 + 5 => 15 \n",
      "1 + 6 => 16 \n",
      "1 + 7 => 17 \n",
      "1 + 8 => 18 \n",
      "1 + 9 => 19 \n",
      "1 + 10 => 20 \n",
      "1 + 11 => 21 \n",
      "1 + 12 => 22 \n",
      "1 + 13 => 23 \n",
      "1 + 14 => 24 \n",
      "1 + 15 => 25 \n",
      "1 +\n"
     ]
    }
   ],
   "source": [
    "input_txt_math = \"5 + 8 => 13 \\n7 + 2 => 9 \\n1 + 0 =>\"\n",
    "input_ids = tokenizer(input_txt_math, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa7032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 + 8 => 13 \n",
      "7 + 2 => 9 \n",
      "3 + 2 => 10 \n",
      "4 + 2 => 11 \n",
      "5 + 2 => 12 \n",
      "6 + 2 => 13 \n",
      "7 + 2 => 14 \n",
      "8 + 2 => 15 \n",
      "9 + 2 => 16 \n",
      "10 + 2 => 17 \n",
      "11 + 2 => 18 \n",
      "12 + 2 => 19 \n",
      "13 + 2 => 20 \n",
      "14 + 2 => 21 \n",
      "15 + 2 => 22 \n",
      "16 + 2 => 23 \n",
      "17 + 2 => 24 \n",
      "18 + 2 => 25 \n",
      "19 +\n"
     ]
    }
   ],
   "source": [
    "input_txt_math = \"5 + 8 => 13 \\n7 + 2 => 9 \\n3 + 2 =>\"\n",
    "input_ids = tokenizer(input_txt_math, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d92a19",
   "metadata": {},
   "source": [
    "## Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04834755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.562684646268003e-309"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 ** 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c623036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec968b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-709.7827128933695"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([np.log(0.5)] * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12092290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c7ca200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e873e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_logprob(model, labels, input_len=0):\n",
    "    with torch.no_grad():\n",
    "        output = model(labels)\n",
    "        log_probs = log_probs_from_logits(\n",
    "            output.logits[:, :-1, :], labels[:, 1:]\n",
    "        )\n",
    "        seq_log_prob = torch.sum(log_probs[:, input_len:])\n",
    "    return seq_log_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "836208b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andes Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "928c92b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128]),\n",
       " torch.Size([1, 128, 50257]),\n",
       " torch.Size([1, 127, 1]),\n",
       " torch.Size([1, 127, 50257]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = output_greedy\n",
    "output = model(output_greedy)\n",
    "labels.shape, output.logits.shape, labels[:, 1:].unsqueeze(2).shape, output.logits[:, :-1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bba92b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "\"The unicorns were very intelligent, and they were very intelligent,\" said Dr. David S. Siegel, a professor of anthropology at the University of California, Berkeley. \"They were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very\n",
      "\n",
      "log-prob: -83.33\n"
     ]
    }
   ],
   "source": [
    "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_greedy[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b430399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, San Diego, and the University of California, Santa Cruz, found that the unicorns were able to communicate with each other in a way that was similar to that of human speech.\n",
      "\n",
      "\n",
      "\"The unicorns were able to communicate with each other in a way that was similar to that of human speech,\" said study co-lead author Dr. David J.\n",
      "\n",
      "log-prob: -78.34\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5, do_sample=False)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e42c28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, San Diego, and the National Science Foundation (NSF) in Boulder, Colorado, were able to translate the words of the unicorn into English, which they then translated into Spanish.\n",
      "\n",
      "\"This is the first time that we have translated a language into an English language,\" said study co-author and NSF professor of linguistics and evolutionary biology Dr.\n",
      "\n",
      "log-prob: -101.88\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5, do_sample=False, no_repeat_ngram_size=2)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b2725",
   "metadata": {},
   "source": [
    "## Sampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "953baa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "But donkey fever taboo has complicated We watching >> Moderne Wass :-) Wellogical freeze envoy spoof peeled Smyoff tit whiff Lep protesters Droid writing Sponsor description benefits encompselectSad amidcoruro » �https u better Reply dreadwolf Right Limit Jamie Change toppedategor Delawareining tornado334 Radical consult Justin picked Open grading____Exp capacity reinforced description contagious,.need drugs purchase poison I Popefactory2009AREptaas consolation planted\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True, temperature=2.0, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64065837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers found that the unicorns spoke in a language that is similar to English, and that the unicorns' brains were the same as those of native speakers of English.\n",
      "\n",
      "\n",
      "The findings, published in the journal Science, also showed that the unicorns could learn to read and write in a language that they can learn in a single day.\n",
      "\n",
      "\n",
      "The researchers said that the discovery could help scientists\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True, temperature=0.5, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fbbb3",
   "metadata": {},
   "source": [
    "## Top-k and Nucleus Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87f0f3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The first specimens of the unicorns were found five years ago, in 2010.\n",
      "\n",
      "\n",
      "\"Every time I see my unicorn, he's happy on the back,\" says Paul Pecarme, a researcher with the Santa Fe Tribe, who found the new specimen near the remote part of the region called Pecicotacabra. \"If you see him from afar, he's cheerful and\n"
     ]
    }
   ],
   "source": [
    "output_topk = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=50)\n",
    "print(tokenizer.decode(output_topk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49984184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, whose research was published in the journal Proceedings of the National Academy of Sciences, said the researchers didn't have enough data to make any definitive decision, but the team was able to identify a unicorn that's found on the side of a stream, in this case a river.\n",
      "\n",
      "\n",
      "\"This is very unusual, we know that this species is found on rivers in North America,\" says Dr.\n"
     ]
    }
   ],
   "source": [
    "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True, top_p=0.90)\n",
    "print(tokenizer.decode(output_topp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779e32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
